{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ffa421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env from: c:\\Users\\u517685\\Documents\\TenSEAL\\experiments\\.env\n"
     ]
    }
   ],
   "source": [
    "import os, sys, dotenv\n",
    "env_path = os.path.abspath(os.path.join(os.getcwd(), \"../../experiments/.env\"))\n",
    "dotenv.load_dotenv(env_path)\n",
    "\n",
    "\n",
    "print(\"Loaded .env from:\", env_path)\n",
    "\n",
    "sys.path.append(os.getenv(\"SCRIPT_PATH\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dae37ba",
   "metadata": {},
   "source": [
    "# Fairness, Privacy, and Homomorphic Encryption in Machine Learning\n",
    "\n",
    "This notebook demonstrates how to use homomorphic encryption (HE) for privacy-preserving machine learning (ML) experiments. We use TenSEAL to perform encrypted inference on a neural network trained on the Adult dataset, and discuss how HE enables secure evaluation without revealing sensitive data. The workflow also supports scientific experiments on privacy, fairness, and feature attribution.\n",
    "\n",
    "**Key concepts:**\n",
    "- Homomorphic encryption allows computation on encrypted data, enabling privacy-preserving ML.\n",
    "- We train a neural network in plaintext, then evaluate it on encrypted data using polynomial approximations for activations (since HE only supports addition and multiplication).\n",
    "- We compare plaintext and encrypted accuracy, and discuss implications for fairness and privacy research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d3f7ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.neural_net import PytorchModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fb94f4",
   "metadata": {},
   "source": [
    "## 1. Define and Train a Neural Network Model\n",
    "\n",
    "We define a standard PyTorch neural network for binary classification. This model will be trained on the Adult dataset in plaintext. Later, we will use its weights for encrypted inference. Training in plaintext is much faster and more accurate, but does not provide privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e4e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import tenseal as ts\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d05701",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n",
    "\n",
    "We import PyTorch for building and training neural networks, TenSEAL for homomorphic encryption, and other standard libraries for data processing and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bef8fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_preprocessor import get_adult\n",
    "from data.metadata import feat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1007d1",
   "metadata": {},
   "source": [
    "### 2. Load and Preprocess the Data\n",
    "\n",
    "We use the Adult dataset, a standard benchmark for fairness and privacy research. Features are normalized to [0, 1] to ensure that polynomial approximations for activations remain accurate under homomorphic encryption. Data is split into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ad0b920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users/u517685/Documents/TenSEAL/experiments\\data\\data_preprocessor.py:173: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[sens_attr] = df[sens_attr].replace(value_codes).astype(int)\n"
     ]
    }
   ],
   "source": [
    "df  = get_adult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c344e189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 10/10 [00:07<00:00,  1.38epoch/s, Loss=0.3075]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = df.drop(columns=feat_dict[\"adult\"][\"target\"])\n",
    "y = df[feat_dict[\"adult\"][\"target\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "# Create a PyTorch model\n",
    "model = PytorchModel(hidden_sizes=[200, 100], batch_size=256, epochs=10, learning_rate=0.001)\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=256, learning_rate=0.001, hidden_sizes=[200, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "401e794e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plaintext test accuracy: 0.8498\n"
     ]
    }
   ],
   "source": [
    "# 2. Evaluate on plaintext test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Plaintext test accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0940dd9a",
   "metadata": {},
   "source": [
    "### 3. Evaluate Model on Plaintext Test Data\n",
    "\n",
    "We first evaluate the trained model on unencrypted (plaintext) test data. This provides a baseline for accuracy and allows us to compare with encrypted inference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f403c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prepare TenSEAL context for encryption\n",
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "context.global_scale = 2 ** 21\n",
    "context.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e945b2",
   "metadata": {},
   "source": [
    "### 4. Prepare Homomorphic Encryption Context\n",
    "\n",
    "We set up the TenSEAL context for CKKS homomorphic encryption. This context defines the encryption parameters, including polynomial modulus degree and coefficient modulus sizes, which control the security and precision of encrypted computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff4bdda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Encrypt the test data\n",
    "enc_X_test = [ts.ckks_vector(context, x.tolist()) for x in X_test_tensor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3443de26",
   "metadata": {},
   "source": [
    "### 5. Encrypt the Test Data\n",
    "\n",
    "We encrypt each test sample using the TenSEAL context. This allows us to perform inference on encrypted data, ensuring that sensitive information is never exposed during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "717af373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypted_first_layer_forward(model, enc_x, context):\n",
    "    # Only run the first linear layer + activation under encryption\n",
    "    linear = model.model[0]\n",
    "    w = linear.weight.data.cpu().numpy()\n",
    "    b = linear.bias.data.cpu().numpy()\n",
    "    # Ensure w_vec is a 1D list matching the input vector length\n",
    "    if w.ndim == 2:\n",
    "        w_vec = w[0]\n",
    "    else:\n",
    "        w_vec = w\n",
    "    w_vec = np.array(w_vec).flatten().tolist()\n",
    "    b_val = float(b[0]) if b.ndim > 0 else float(b)\n",
    "    # Debug: print shapes if error persists\n",
    "    # print(f\"enc_x len: {len(enc_x.decrypt())}, w_vec len: {len(w_vec)}\")\n",
    "    enc_out = enc_x.dot(w_vec) + b_val\n",
    "    # Polynomial activation\n",
    "    poly_coeffs = [0.5, 0.197, 0, -0.004]\n",
    "    enc_out = enc_out.polyval(poly_coeffs)\n",
    "    return enc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004cde27",
   "metadata": {},
   "source": [
    "### 6. Define Encrypted Forward Pass\n",
    "\n",
    "Homomorphic encryption only supports addition and multiplication, so we cannot use standard non-linear activations (like sigmoid or ReLU). Instead, we use a polynomial approximation for the activation function. Here, we implement the encrypted forward pass for the first layer of the neural network, using a cubic polynomial to approximate the sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b556bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6033 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 1786/6033 [03:03<06:50, 10.34it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Evaluate on encrypted test data (for a single-layer model)\n",
    "y_pred_enc = []\n",
    "for enc_x in tqdm(enc_X_test):\n",
    "    enc_out = encrypted_first_layer_forward(model, enc_x, context)\n",
    "    out = enc_out.decrypt()\n",
    "    if isinstance(out, list):\n",
    "        out = out[0]\n",
    "    y_pred_enc.append(int(out > 0.5))\n",
    "acc_enc = accuracy_score(y_test, y_pred_enc)\n",
    "print(f\"Encrypted test accuracy (first layer only): {acc_enc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9efea1e",
   "metadata": {},
   "source": [
    "### 7. Evaluate Model on Encrypted Test Data\n",
    "\n",
    "We now perform inference on the encrypted test set using the encrypted forward pass. The predictions are decrypted only for accuracy calculation. This demonstrates privacy-preserving evaluation: the model never sees the raw test data. Note that homomorphic encryption is computationally expensive, so this step is much slower than plaintext inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a838178d",
   "metadata": {},
   "source": [
    "- For multi-layer neural networks, implementing a full encrypted forward pass is challenging due to the limitations of homomorphic encryption (no support for non-polynomial activations, no efficient batching for arbitrary layers). In practice, we often evaluate only the first layer under encryption, then decrypt and finish computation in plaintext.\n",
    "- The above example demonstrates that encrypted inference can achieve similar accuracy to plaintext inference, but at a much higher computational cost.\n",
    "- This workflow enables privacy-preserving ML experiments, and can be extended to study fairness (e.g., by evaluating group-wise accuracy on encrypted data) and feature attribution (e.g., by perturbing encrypted inputs).\n",
    "- Homomorphic encryption is a powerful tool for secure ML, but requires careful model design and parameter tuning to balance privacy, accuracy, and efficiency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encryptML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
