{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ffa421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env from: c:\\Users\\u517685\\Documents\\TenSEAL\\experiments\\.env\n"
     ]
    }
   ],
   "source": [
    "import os, sys, dotenv\n",
    "env_path = os.path.abspath(os.path.join(os.getcwd(), \"../../experiments/.env\"))\n",
    "dotenv.load_dotenv(env_path)\n",
    "\n",
    "\n",
    "print(\"Loaded .env from:\", env_path)\n",
    "\n",
    "sys.path.append(os.getenv(\"SCRIPT_PATH\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dae37ba",
   "metadata": {},
   "source": [
    "# Fairness, Privacy, and Homomorphic Encryption in Machine Learning\n",
    "\n",
    "This notebook hows how to use homomorphic encryption (HE) for privacy-preserving machine learning (ML) experiments. We use TenSEAL to perform encrypted inference on a neural network trained on the Adult dataset, and discuss how HE enables secure evaluation without revealing sensitive data. \n",
    "\n",
    "**Key concepts:**\n",
    "- Homomorphic encryption allows computation on encrypted data, enabling privacy-preserving ML.\n",
    "- HE only supports addition and multiplication, so we use polynomial approximations for activations (e.g., cubic sigmoid) instead of standard non-linearities.\n",
    "- In deep models, only the first layer is typically evaluated under encryption; the rest is done in plaintext after decryption, due to HE limitations.\n",
    "- We compare plaintext and encrypted accuracy, and discuss implications for fairness and privacy research.\n",
    "- There is a tradeoff between privacy and computational efficiency: encrypted inference is much slower than plaintext, but protects sensitive data throughout computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35537ab1",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary >Scientific Context: Homomorphic Encryption and Deep Neural Networks </summary>\n",
    "\n",
    "Homomorphic encryption (HE) enables computation on encrypted data, but it comes with important limitations for deep learning:\n",
    "\n",
    "- **Supported Operations:** HE schemes like CKKS only support addition and multiplication. This means that only polynomial functions can be computed directly on encrypted data.\n",
    "- **Activation Functions:** Standard neural network activations (e.g., sigmoid, ReLU, tanh) are not polynomials. To use them under HE, we must approximate them with low-degree polynomials (e.g., cubic sigmoid), which are only accurate within a certain input range.\n",
    "- **Depth Limitation:** Each multiplication increases the \"noise\" in ciphertexts. As a result, only a limited number of layers (typically just the first linear + activation) can be run under encryption before decryption is required. The rest of the network must be evaluated in plaintext after decryption.\n",
    "- **Tradeoff:** There is a fundamental tradeoff between privacy and computational efficiency. Encrypted inference is much slower and more resource-intensive than plaintext, but it protects sensitive data throughout computation.\n",
    "</details>  \n",
    "\n",
    "**In this notebook:**\n",
    "- We show encrypted inference by running the first layer of a neural network under HE, using a polynomial activation.\n",
    "- We compare the results to plaintext inference, and discuss the implications for privacy, fairness, and scientific research.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d3f7ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.neural_net import PytorchModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fb94f4",
   "metadata": {},
   "source": [
    "## 1. Define and Train a Neural Network Model\n",
    "\n",
    "We define a standard PyTorch neural network for binary classification. This model will be trained on the Adult dataset in plaintext. Later, we will use its weights for encrypted inference. Training in plaintext is much faster and more accurate, but does not provide privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e4e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import tenseal as ts\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d05701",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n",
    "\n",
    "We import PyTorch for building and training neural networks, TenSEAL for homomorphic encryption, and other standard libraries for data processing and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bef8fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_preprocessor import get_adult\n",
    "from data.metadata import feat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1007d1",
   "metadata": {},
   "source": [
    "### 2. Load and Preprocess the Data\n",
    "\n",
    "We use the Adult dataset, a standard benchmark for fairness and privacy research. Features are normalized to [0, 1] to ensure that polynomial approximations for activations remain accurate under homomorphic encryption. Data is split into training and test sets.\n",
    "\n",
    "**Note:** Normalization is essential because polynomial approximations (like our cubic sigmoid) are only accurate within a certain input range. If features are not normalized, encrypted inference can become unstable or inaccurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1c44cf",
   "metadata": {},
   "source": [
    "#### Why Normalization Matters for Encrypted Neural Networks\n",
    "\n",
    "Polynomial approximations of activation functions (like cubic sigmoid) are only accurate within a certain input range (e.g., [-5, 5]).\n",
    "\n",
    "- If the pre-activation values (inputs to the polynomial) are outside this range, the approximation becomes inaccurate, leading to poor predictions.\n",
    "- Normalizing features to [0, 1] (or standardizing to mean 0, std 1) helps ensure that the values passed to the polynomial activation remain within the valid range.\n",
    "- Regularization of model weights can also help keep pre-activation values small during training.\n",
    "\n",
    "**Best practice:** Always check the distribution of pre-activation values before running encrypted inference, and adjust normalization or regularization as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ad0b920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users/u517685/Documents/TenSEAL/experiments\\data\\data_preprocessor.py:173: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[sens_attr] = df[sens_attr].replace(value_codes).astype(int)\n"
     ]
    }
   ],
   "source": [
    "df  = get_adult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c344e189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 10/10 [00:04<00:00,  2.09epoch/s, Loss=0.3239]\n",
      "Training Progress: 100%|██████████| 10/10 [00:04<00:00,  2.09epoch/s, Loss=0.3239]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = df.drop(columns=feat_dict[\"adult\"][\"target\"])\n",
    "y = df[feat_dict[\"adult\"][\"target\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "# Create a PyTorch model\n",
    "model = PytorchModel(hidden_sizes=[200], batch_size=256, epochs=10, learning_rate=0.001)\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=256, learning_rate=0.001, hidden_sizes=[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d00e1947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHFCAYAAAAUpjivAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARwFJREFUeJzt3XlcVdXi///3SWYEBAeQnM00BUuxnCpUnMe0rprlkHSza5mUfhs/pd5PD0y9qd1rphWCZU6ZNpnmrHmlwjm1wcwcEsQMwREQ1u8Pf5yPh0k4HgW3r+fjcR4Pz9rr7L3WPpvt+6yz9j42Y4wRAACARd1S1g0AAAC4lgg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7AADA0gg7N7iEhATZbDb7w8vLSyEhIWrfvr0mTpyo1NTUAq8ZP368bDZbqbZz7tw5jR8/Xhs2bCjV6wrbVp06ddSzZ89SredK5s+fr+nTpxe6zGazafz48S7dnqutXbtWLVq0kK+vr2w2mz799NNC6/3+++8O7/ctt9yiypUrq3v37kpMTLy+jZbUvHlz2Ww2/etf/3J6HV999VWR70+dOnU0bNgwp9d9JcUd13l/W7///vs1235+J06ckIeHhwYOHFhknYyMDPn4+Kh3794lXm9Z9KW0Tp06pSpVqmjhwoX2srzzR2GPGTNmaMOGDbLZbKU+LxUnNja2yL+/wthsNj399NMu2/718uqrr6p58+bKzc0t66ZcHwY3tPj4eCPJxMfHm8TERLNp0yazZMkSExMTYwICAkxQUJBZvXq1w2uOHDliEhMTS7WdEydOGElm3LhxpXpdYduqXbu26dGjR6nWcyU9evQwtWvXLnRZYmKiOXLkiEu350q5ubkmKCjItGrVyqxZs8YkJiaav/76q9C6Bw8eNJLMqFGjTGJiotm8ebOZPXu2CQ0NNZ6enmb79u3Xrd07duwwkowk06hRI6fX89RTT5miTkXbt283v/76q9PrvpLijuvU1FSTmJhoLly4cM22X5gHH3zQeHp6FnkMzJ4920gyn376aYnXmXeeOHjwoIta6XoxMTEmPDzc5Obm2svGjRtnJJmVK1eaxMREh0dKSopJT083iYmJJj093WXt8PX1NUOHDi1xfUnmqaeectn2r5dTp06ZSpUqmTlz5pR1U64LtzLKWHCxsLAwtWjRwv78wQcf1LPPPqt7771X/fr10/79+xUcHCxJqlGjhmrUqHFN23Pu3Dn5+Phcl21dSatWrcp0+1dy7Ngx/fXXX+rbt6+ioqJK9JpatWrZ+9W2bVvddtttioqK0syZM/Xee+8V+prz58/Ly8ur1KN6RXn//fclST169NDy5cu1ZcsWtWnTxiXrztOsWTOXrq80qlatqqpVq1737UZHR+uTTz7RRx99VOiIwZw5cxQcHKwePXpc97ZdK3/99Zdmz56tadOmFXp8RkREqEqVKoW+tiR/33nnI/zfvggICNCjjz6qN954Q8OGDXPZeaHcKuu0hauT94ktKSmp0OWLFy82ksyECRPsZXmfli63du1aExkZaYKCgoyXl5epWbOm6devnzl79qx9NCH/I+/TT976tm3bZh588EFTqVIlExISUuS28kZ2li5dasLDw42np6epW7eueeuttwrtW/5Po+vXrzeSzPr1640xxkRGRhbavjwq5JP7Dz/8YHr37m0qVapkPD09zZ133mkSEhIK3c78+fPNyy+/bKpXr278/PxMVFSU+emnnwrd3/l98803pkOHDqZixYrG29vbtG7d2nz55ZcF3ovLH0WNUBnzfyM7U6ZMcSg/e/askWQ6derksO++/vpr89hjj5kqVaoYSeb8+fPGGGMWLlxoWrVqZXx8fIyvr6/p3LlzqUaFzp8/bwIDA01ERIT55ZdfjCQTHR1daN0VK1aYDh06GH9/f+Pt7W0aNWpkYmNjjTHGDB06tND3Lu89r127tv04S01NNe7u7uZ//ud/Cmzjxx9/NJLsx1Bqaqr5xz/+Ye644w7j6+trqlatatq3b282bdpUYF8WdVwXdfzFxcWZpk2bGk9PTxMYGGgeeOABs2/fPoc6Q4cONb6+vmb//v2mW7duxtfX19SoUcM899xzVxwpysnJMTVq1DDNmzcvsGzfvn1Gkvl//+//GWOMWbVqlendu7e59dZbjaenp6lfv7554oknzIkTJxxeV1hfLt+3l4uMjDSRkZEOZenp6WbMmDGmTp06xt3d3YSGhprRo0ebM2fOONRbvHixueeee+zvdd26dc1jjz1WbH+NMebNN9807u7uJi0tzaE87+8jf3/y5D8XGPN/+3737t2mU6dOpmLFiqZVq1bGmEsjhT169DBVq1Y1Hh4epnr16qZ79+72kd/Cjof8+yI/lWBkZ+HChaZTp04mJCTEeHl5mUaNGpkXXnjBYf998MEHRpLZsmVLgddPmDDBuLm5mT/++MNetnr1atOhQwfj5+dnvL29TZs2bcyaNWsK3X+FnZuNMea7774zkszatWuLbb8VMGfH4rp3764KFSpo06ZNRdb5/fff1aNHD3l4eGjOnDlauXKl3njjDfn6+iorK0vVq1fXypUrJV361JmYmKjExES9+uqrDuvp16+fbrvtNn388ceaNWtWse3auXOnYmJi9Oyzz2rZsmVq06aNRo8e7dTcj5kzZ6pt27YKCQmxt624+Ss///yz2rRpo7179+rf//63li5dqsaNG2vYsGGaPHlygfovv/yyDh06pPfff1/vvvuu9u/fr169eiknJ6fYdm3cuFEdOnRQenq64uLitGDBAvn5+alXr15atGiRJOnxxx/X0qVLJUmjRo1SYmKili1bVup98Ouvv0pSgZGI4cOHy93dXR9++KGWLFkid3d3xcbG6uGHH1bjxo21ePFiffjhhzp9+rTuu+8+7du3r0TbW7p0qdLS0jR8+HA1aNBA9957rxYtWqQzZ8441IuLi1P37t2Vm5urWbNm6YsvvtAzzzyjo0ePSro0b+Chhx6SJIf3rnr16gW2WbVqVfXs2VNz584tMM8gPj5eHh4eeuSRRyRdGimQpHHjxmn58uWKj49XvXr11K5dO/v8jpIe15ebOHGioqOj1aRJEy1dulRvvfWWdu/erdatW2v//v0OdbOzs9W7d29FRUXps88+0/DhwzVt2jRNmjSp2H17yy23aNiwYdq+fbt27dpVoJ/SpfdVkg4cOKDWrVvrnXfe0apVq/Taa6/pu+++07333qvs7Oxit1NS586dU2RkpObOnatnnnlGK1as0AsvvKCEhAT17t1bxhhJl96/AQMGqF69elq4cKGWL1+u1157TRcvXrziNpYvX65mzZqpUqVKhS7PycnRxYsX7Y8r/e1lZWWpd+/e6tChgz777DNNmDBBZ8+eVadOnXT8+HG9/fbbWr16taZPn65atWrp9OnT9j54e3vb58AlJiZq5syZpdthhdi/f7+6d++uuLg4rVy5UjExMVq8eLF69eplrzNgwACFhITo7bffdnjtxYsXNXv2bPXt21ehoaGSpHnz5qlz587y9/fX3LlztXjxYgUFBalLly5au3Ztge0XdW6OiIhQxYoVtXz58qvuY7lX1mkLV+dKIzvGGBMcHGzuuOMO+/P8oy1LliwxkszOnTuLXEdxcxvy1vfaa68VuexytWvXNjabrcD2OnXqZPz9/c3Zs2cd+nalkR1jip+zk7/dAwcONJ6enubw4cMO9bp162Z8fHzMqVOnHLbTvXt3h3p5o2VXmvfUqlUrU61aNXP69Gl72cWLF01YWJipUaOGfW5CUaM1hcmrO2nSJJOdnW0uXLhgtm3bZu6++24jySxfvtwY83/7bsiQIQ6vP3z4sHFzczOjRo1yKD99+rQJCQkx/fv3v2IbjDGmQ4cOxsvLy/5JPG97cXFxDuv09/c39957r8M8jPyKm7OTf/Th888/N5LMqlWr7GUXL140oaGh5sEHHyxyGxcvXjTZ2dkmKirK9O3b115e3HGd//hLS0sz3t7eBY6Hw4cPG09PTzNo0CB7Wd6I1eLFix3qdu/e3TRs2LDIdub57bffjM1mM88884y9LDs724SEhJi2bdsW+prc3FyTnZ1tDh06ZCSZzz77rMi+GFPykZ2JEyeaW265pcA5Ju+88dVXXxljjPnXv/5lJNn/fkrDx8fHPPnkkwXKCxv5lGRuvfVWY0zRIzuSCsxF2bp1a4nmOl3rOTt579PGjRuNJLNr1y77snHjxhkPDw9z/Phxe9miRYuMJLNx40ZjzKVR3KCgINOrVy+H9ebk5Jg777zT3HPPPQ7rK+rcnKdt27amZcuWJW7/jYqRnZuA+f8/eRXlrrvukoeHh5544gnNnTtXv/32m1PbefDBB0tct0mTJrrzzjsdygYNGqSMjAxt377dqe2X1Lp16xQVFaWaNWs6lA8bNkznzp0rMCqU/6qXpk2bSpIOHTpU5DbOnj2r7777Tg899JAqVqxoL69QoYIGDx6so0eP6ueff3a6Dy+88ILc3d3l5eWliIgIHT58WLNnz1b37t0d6uV/T77++mtdvHhRQ4YMcfik7OXlpcjISPuohzHGYfnln84PHjyo9evXq1+/fvZP4n/729/k5+enOXPm2Ott2bJFGRkZGjlypMvmA3Tr1k0hISH2EY68Ph07dsw+2pFn1qxZat68uby8vOTm5iZ3d3etXbtWP/74o1PbTkxM1Pnz5wtcHVazZk116NChwCdqm83m8MldunTsFHfc5Klbt67at2+vjz76SFlZWZKkFStWKCUlxaGfqampevLJJ1WzZk17H2vXri1JTvczvy+//FJhYWG66667HI6HLl26OFwJdffdd0uS+vfvr8WLF+uPP/4o0fpPnTqlc+fOqVq1akXWWbNmjZKSkuyPr7766orrzX/s33bbbQoMDNQLL7ygWbNmlXgU0xV+++03DRo0SCEhIapQoYLc3d0VGRkpyfF9+sc//iFJDvPuZsyYofDwcN1///2SLv1d/fXXXxo6dKjD+5Gbm6uuXbsqKSlJZ8+eddh+cefmatWqlfi9upERdizu7NmzOnnypH34szD169fXmjVrVK1aNT311FOqX7++6tevr7feeqtU2yrsq4eihISEFFl28uTJUm23tE6ePFloW/P2Uf7tV65c2eG5p6enpEsTfouSlpYmY0yptlMao0ePVlJSkrZt26YDBw4oOTlZTzzxRIF6+bd//PhxSZf+Y3J3d3d4LFq0SH/++aekS1/B5V+ed9nynDlzZIzRQw89pFOnTunUqVP2r2z++9//6qeffpJ06TJqSS6doO7m5qbBgwdr2bJlOnXqlKRLl1VXr15dXbp0sdebOnWq/vGPf6hly5b65JNP9O233yopKUldu3Yt9n0rTt77VdR7mv/99PHxkZeXl0OZp6enLly4UKLtRUdH6+TJk/r8888lXfoKq2LFiurfv78kKTc3V507d9bSpUv1/PPPa+3atfr+++/17bffSir++CyN48ePa/fu3QWOBz8/Pxlj7MfM/fffr08//dQepmvUqKGwsDAtWLCg2PXntTP/vrrcnXfeqRYtWtgfeR84iuLj4yN/f3+HsoCAAG3cuFF33XWXXn75ZTVp0kShoaEaN26cy77yK8yZM2d033336bvvvtPrr7+uDRs2KCkpyf719eXvU3BwsAYMGKDZs2crJydHu3fv1jfffOMwUT3vb/ihhx4q8J5MmjRJxhj717h5ijs3e3l5uexYKc+4Gsvili9frpycHLVr167Yevfdd5/uu+8+5eTkaOvWrfrPf/6jmJgYBQcHF3vPj8uV5tN7SkpKkWV54SLv5JeZmelQL+/k6qzKlSsrOTm5QPmxY8ckqcirPkojMDBQt9xyyzXbTo0aNRyuvitK/vckb5tLliyxjwAUJiIiQklJSQ5loaGhys3NVUJCgqRL8wAKM2fOHE2ePNk+fyhvfo6rPPbYY5oyZYoWLlyoAQMG6PPPP1dMTIwqVKhgrzNv3jy1a9dO77zzjsNr8+ZmOCPvuCzqPXXFcXO5fv36KTAwUHPmzFFkZKS+/PJLDRkyxD5SuGfPHu3atUsJCQkaOnSo/XV587euxMvLq8DflnTp7+vyvlSpUkXe3t4Oo3aXu7xunz591KdPH2VmZurbb7/VxIkTNWjQINWpU0etW7cu9PV5+zX/f9BXo6hzUXh4uBYuXChjjHbv3q2EhAT985//lLe3t1588UWXbf9y69at07Fjx7Rhwwb7aI4ke1jPb/To0frwww/12WefaeXKlapUqZJ9Lpr0f/v7P//5T5FXouVdeZunuHPzX3/95fJjtzwi7FjY4cOHNXbsWAUEBGjEiBElek2FChXUsmVLNWrUSB999JG2b9+ugQMHlmg0ozT27t2rXbt2OXyVNX/+fPn5+al58+aSLt1QTpJ2796thg0b2uvlfdK9nKenZ4nbFhUVpWXLlunYsWMOI14ffPCBfHx8XHKpuq+vr1q2bKmlS5fqX//6l7y9vSVd+jQ+b9481ahRQ7fffvtVb6e0unTpIjc3Nx04cKDYoW0/P79Cw9SKFSt09OhRPfXUU/aJxZd7+umn9cEHHyg2NlZt2rRRQECAZs2apYEDBxZ5wr382MrbT8W544471LJlS8XHxysnJ0eZmZl67LHHHOrYbDb7evPs3r1biYmJDl9flua4bt26tby9vTVv3jz97W9/s5cfPXpU69atK3R/XA0vLy8NGjRIs2bN0qRJk5Sdne3wFVbe/szfz9mzZ5do/XXq1NHu3bsdyn755Rf9/PPPDv/59ezZU7GxsapcubLq1q1bonV7enoqMjJSlSpV0tdff60dO3YUGXY8PDxUr149HThwoETrdgWbzaY777xT06ZNU0JCgsNX56U5l5R0W3nrvVxR71NERITatGmjSZMmac+ePXriiSfk6+trX962bVtVqlRJ+/btc8nNDH/77TeFhYVd9XrKO8KORezZs8f+3W1qaqq++eYbxcfHq0KFClq2bFmx9wuZNWuW1q1bpx49eqhWrVq6cOGC/VNcx44dJV36z6927dr67LPPFBUVpaCgIFWpUsUeSEorNDRUvXv31vjx41W9enXNmzdPq1ev1qRJk+z3w7j77rvVsGFDjR07VhcvXlRgYKCWLVumzZs3F1hfeHi4li5dqnfeeUcRERG65ZZbihz5GDdunL788ku1b99er732moKCgvTRRx9p+fLlmjx5sgICApzqU34TJ05Up06d1L59e40dO1YeHh6aOXOm9uzZowULFpTJfS3q1Kmjf/7zn3rllVf022+/qWvXrgoMDNTx48f1/fffy9fXVxMmTCjy9XFxcXJzc9PLL79c6FejI0aM0DPPPKPly5erT58+evPNN/X444+rY8eO+vvf/67g4GD9+uuv2rVrl2bMmCHp0nsnSZMmTVK3bt1UoUIFNW3aVB4eHkW2Y/jw4RoxYoSOHTumNm3aOIRh6dJ/0P/7v/+rcePGKTIyUj///LP++c9/qm7dug7zj0pzXFeqVEmvvvqqXn75ZQ0ZMkQPP/ywTp48qQkTJsjLy0vjxo0rdt87Izo6Wm+//bamTp2qRo0aOdzHqFGjRqpfv75efPFFGWMUFBSkL774QqtXry7RugcPHqxHH31UI0eO1IMPPqhDhw45jMjliYmJ0SeffKL7779fzz77rJo2barc3FwdPnxYq1at0pgxY9SyZUu99tprOnr0qKKiolSjRg2dOnVKb731lsP8lKK0a9dOK1asKP0OKoUvv/xSM2fO1AMPPKB69erJGKOlS5fq1KlT6tSpk71eeHi4NmzYoC+++ELVq1eXn59fgeMrvwMHDmjJkiUFyhs3bqw2bdooMDBQTz75pMaNGyd3d3d99NFHBa60u9zo0aM1YMAA2Ww2jRw50mFZxYoV9Z///EdDhw7VX3/9pYceekjVqlXTiRMntGvXLp04caLAiGZRTp48qf3792vUqFElqn9DK7Op0XCJvKss8h4eHh6mWrVqJjIy0sTGxprU1NQCr8l/hVRiYqLp27evqV27tvH09DSVK1c2kZGR5vPPP3d43Zo1a0yzZs2Mp6dnoffZKexeGMXdZ2fJkiWmSZMmxsPDw9SpU8dMnTq1wOt/+eUX07lzZ+Pv72+qVq1qRo0aZZYvX17gCoy//vrLPPTQQ6ZSpUrGZrOV6D47vXr1MgEBAcbDw8PceeedJj4+3qFO3pUeH3/8sUN53hVR+esXJu8+O76+vsbb29u0atXKfPHFF4WurzRXY12p7pWu0vv0009N+/btjb+/v/H09DS1a9c2Dz30UIH7dFzuxIkTxsPDwzzwwANF1sm7YunyK0W++uorExkZaXx9fY2Pj49p3LixmTRpkn15Zmamefzxx03VqlXt711h99m5XHp6uvH29jaSzHvvvVdgeWZmphk7dqy59dZbjZeXl2nevLn59NNPzdChQwtctVfUcV3U1YDvv/++adq0qfHw8DABAQGmT58+Zu/evQ518u71kl9hfw9X0qxZMyPJTJ48ucCyffv2mU6dOhk/Pz8TGBho/va3v5nDhw8XOOYL60tubq6ZPHmyqVevnvHy8jItWrQw69atK/Q+O2fOnDH/8z//Yxo2bGjvd3h4uHn22WdNSkqKMcaYL7/80nTr1s3ceuut9vNQ9+7dzTfffHPFPq5du9ZIMt9//71D+dXcZye/n376yTz88MOmfv36xtvb2wQEBJh77rmnwP21du7cadq2bWt8fHxKfJ+doh5578GWLVtM69atjY+Pj6latap5/PHHzfbt24s8j2RmZhpPT0/TtWvXIre7ceNG06NHDxMUFGTc3d3Nrbfeanr06OFwvrrS/ouLizPu7u7299DKbMZc4VIdAACusaZNm6pt27YlHpWwsi+++EK9e/fW8uXLC1xh6Ur33XefatWqpY8++uiabaO8IOwAAMrcypUr1bdvX+3fv7/Mf2KmrOzbt0+HDh3S6NGj5evrq+3bt1+zr7s3bdqkzp07a9++fapXr9412UZ5wqXnAIAy17VrV02ZMkUHDx4s66aUmZEjR6p3794KDAy85vP6Tp48qQ8++OCmCDoSIzsAAMDiGNkBAACWRtgBAACWRtgBAACWxk0FdemutseOHZOfn1+Z3OgNAACUnjFGp0+fVmhoqG65pejxG8KOLv2uTf5fwAYAADeGI0eOFHvLAsKOLt0yXrq0s/L/Ui4AACifMjIyVLNmTfv/40Uh7Oj/fqjN39+fsAMAwA3mSlNQmKAMAAAsjbADAAAsjbADAAAsrUzDzvjx42Wz2RweISEh9uXGGI0fP16hoaHy9vZWu3bttHfvXod1ZGZmatSoUapSpYp8fX3Vu3dvHT169Hp3BQAAlFNlPrLTpEkTJScn2x8//PCDfdnkyZM1depUzZgxQ0lJSQoJCVGnTp10+vRpe52YmBgtW7ZMCxcu1ObNm3XmzBn17NlTOTk5ZdEdAABQzpT51Vhubm4Oozl5jDGaPn26XnnlFfXr10+SNHfuXAUHB2v+/PkaMWKE0tPTFRcXpw8//FAdO3aUJM2bN081a9bUmjVr1KVLl+vaFwAAUP6U+cjO/v37FRoaqrp162rgwIH67bffJEkHDx5USkqKOnfubK/r6empyMhIbdmyRZK0bds2ZWdnO9QJDQ1VWFiYvQ4AALi5lenITsuWLfXBBx/o9ttv1/Hjx/X666+rTZs22rt3r1JSUiRJwcHBDq8JDg7WoUOHJEkpKSny8PBQYGBggTp5ry9MZmamMjMz7c8zMjJc1SUAAFDOlGnY6datm/3f4eHhat26terXr6+5c+eqVatWkgreKMgYc8WbB12pzsSJEzVhwoSraDkAALhRlPnXWJfz9fVVeHi49u/fb5/Hk3+EJjU11T7aExISoqysLKWlpRVZpzAvvfSS0tPT7Y8jR464uCcAAKC8KFdhJzMzUz/++KOqV6+uunXrKiQkRKtXr7Yvz8rK0saNG9WmTRtJUkREhNzd3R3qJCcna8+ePfY6hfH09LT/NAQ/EQEAgLWV6ddYY8eOVa9evVSrVi2lpqbq9ddfV0ZGhoYOHSqbzaaYmBjFxsaqQYMGatCggWJjY+Xj46NBgwZJkgICAhQdHa0xY8aocuXKCgoK0tixYxUeHm6/OgsAANzcyjTsHD16VA8//LD+/PNPVa1aVa1atdK3336r2rVrS5Kef/55nT9/XiNHjlRaWppatmypVatWOfy66bRp0+Tm5qb+/fvr/PnzioqKUkJCgipUqFBW3QIAAOWIzRhjyroRZS0jI0MBAQFKT0/nKy0AAG4QJf3/u1zN2QEAAHC1Mr+DMoCrF52QdMU6ccPuvg4tAYDyh5EdAABgaYzsADcJRn8A3KwY2QEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJZG2AEAAJbmVtYNAGA90QlJV6wTN+zu69ASAGBkBwAAWBwjOwDsGJEBYEWM7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsrN2Fn4sSJstlsiomJsZcZYzR+/HiFhobK29tb7dq10969ex1el5mZqVGjRqlKlSry9fVV7969dfTo0evcegAAUF6Vi7CTlJSkd999V02bNnUonzx5sqZOnaoZM2YoKSlJISEh6tSpk06fPm2vExMTo2XLlmnhwoXavHmzzpw5o549eyonJ+d6dwMAAJRDZR52zpw5o0ceeUTvvfeeAgMD7eXGGE2fPl2vvPKK+vXrp7CwMM2dO1fnzp3T/PnzJUnp6emKi4vTm2++qY4dO6pZs2aaN2+efvjhB61Zs6asugQAAMqRMg87Tz31lHr06KGOHTs6lB88eFApKSnq3LmzvczT01ORkZHasmWLJGnbtm3Kzs52qBMaGqqwsDB7ncJkZmYqIyPD4QEAAKypTO+gvHDhQm3fvl1JSQXv2pqSkiJJCg4OdigPDg7WoUOH7HU8PDwcRoTy6uS9vjATJ07UhAkTrrb5AADgBlBmIztHjhzR6NGjNW/ePHl5eRVZz2azOTw3xhQoy+9KdV566SWlp6fbH0eOHCld4wEAwA2jzMLOtm3blJqaqoiICLm5ucnNzU0bN27Uv//9b7m5udlHdPKP0KSmptqXhYSEKCsrS2lpaUXWKYynp6f8/f0dHgAAwJrKLOxERUXphx9+0M6dO+2PFi1a6JFHHtHOnTtVr149hYSEaPXq1fbXZGVlaePGjWrTpo0kKSIiQu7u7g51kpOTtWfPHnsdAABwcyuzOTt+fn4KCwtzKPP19VXlypXt5TExMYqNjVWDBg3UoEEDxcbGysfHR4MGDZIkBQQEKDo6WmPGjFHlypUVFBSksWPHKjw8vMCEZwAAcHMq0wnKV/L888/r/PnzGjlypNLS0tSyZUutWrVKfn5+9jrTpk2Tm5ub+vfvr/PnzysqKkoJCQmqUKFCGbYccJ3ohIIT+AEAJWczxpiybkRZy8jIUEBAgNLT05m/g3KnvIWduGF3X7FOSdpckvUAQHFK+v93md9nBwAA4Foi7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEtzK+sGADez6ISksm4CAFgeIzsAAMDSGNkBUCZKMqoVN+zu69ASAFbHyA4AALA0wg4AALA0wg4AALA0wg4AALA0wg4AALA0rsYCUCrcGwjAjYaRHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGmEHQAAYGllGnbeeecdNW3aVP7+/vL391fr1q21YsUK+3JjjMaPH6/Q0FB5e3urXbt22rt3r8M6MjMzNWrUKFWpUkW+vr7q3bu3jh49er27AgAAyqkyDTs1atTQG2+8oa1bt2rr1q3q0KGD+vTpYw80kydP1tSpUzVjxgwlJSUpJCREnTp10unTp+3riImJ0bJly7Rw4UJt3rxZZ86cUc+ePZWTk1NW3QIAAOWIzRhjSvuigwcPqm7duteiPQoKCtKUKVM0fPhwhYaGKiYmRi+88IKkS6M4wcHBmjRpkkaMGKH09HRVrVpVH374oQYMGCBJOnbsmGrWrKmvvvpKXbp0KdE2MzIyFBAQoPT0dPn7+1+TfgGFiU5IKusmlGtxw+4u6yYAKMdK+v+3UyM7t912m9q3b6958+bpwoULTjfycjk5OVq4cKHOnj2r1q1b6+DBg0pJSVHnzp3tdTw9PRUZGaktW7ZIkrZt26bs7GyHOqGhoQoLC7PXKUxmZqYyMjIcHgAAwJqcCju7du1Ss2bNNGbMGIWEhGjEiBH6/vvvnWrADz/8oIoVK8rT01NPPvmkli1bpsaNGyslJUWSFBwc7FA/ODjYviwlJUUeHh4KDAwssk5hJk6cqICAAPujZs2aTrUdAACUf06FnbCwME2dOlV//PGH4uPjlZKSonvvvVdNmjTR1KlTdeLEiRKvq2HDhtq5c6e+/fZb/eMf/9DQoUO1b98++3KbzeZQ3xhToCy/K9V56aWXlJ6ebn8cOXKkxO0FAAA3lquaoOzm5qa+fftq8eLFmjRpkg4cOKCxY8eqRo0aGjJkiJKTk6+4Dg8PD912221q0aKFJk6cqDvvvFNvvfWWQkJCJKnACE1qaqp9tCckJERZWVlKS0srsk5hPD097VeA5T0AAIA1uV3Ni7du3ao5c+Zo4cKF8vX11dixYxUdHa1jx47ptddeU58+fUr99ZYxRpmZmapbt65CQkK0evVqNWvWTJKUlZWljRs3atKkSZKkiIgIubu7a/Xq1erfv78kKTk5WXv27NHkyZOvpmvAVWPyMQCUD06FnalTpyo+Pl4///yzunfvrg8++EDdu3fXLbdcGiiqW7euZs+erUaNGhW7npdfflndunVTzZo1dfr0aS1cuFAbNmzQypUrZbPZFBMTo9jYWDVo0EANGjRQbGysfHx8NGjQIElSQECAoqOjNWbMGFWuXFlBQUEaO3aswsPD1bFjR2e6BgAALMapsPPOO+9o+PDheuyxx+xfN+VXq1YtxcXFFbue48ePa/DgwUpOTlZAQICaNm2qlStXqlOnTpKk559/XufPn9fIkSOVlpamli1batWqVfLz87OvY9q0aXJzc1P//v11/vx5RUVFKSEhQRUqVHCmawAAwGKcus+O1XCfHVwLfI119bjPDoDiXNP77MTHx+vjjz8uUP7xxx9r7ty5zqwSAADgmnAq7LzxxhuqUqVKgfJq1aopNjb2qhsFAADgKk6FnUOHDhX6cxG1a9fW4cOHr7pRAAAAruJU2KlWrZp2795doHzXrl2qXLnyVTcKAADAVZwKOwMHDtQzzzyj9evXKycnRzk5OVq3bp1Gjx6tgQMHurqNAAAATnPq0vPXX39dhw4dUlRUlNzcLq0iNzdXQ4YMYc4OAAAoV5wKOx4eHlq0aJH+93//V7t27ZK3t7fCw8NVu3ZtV7cPAADgqlzVz0Xcfvvtuv32213VFgAAAJdzKuzk5OQoISFBa9euVWpqqnJzcx2Wr1u3ziWNAwAAuFpOhZ3Ro0crISFBPXr0UFhYmGw2m6vbBQAA4BJOhZ2FCxdq8eLF6t69u6vbAwB2JfnJDX5SAsCVOHXpuYeHh2677TZXtwUAAMDlnAo7Y8aM0VtvvSV+QxQAAJR3Tn2NtXnzZq1fv14rVqxQkyZN5O7u7rB86dKlLmkcAADA1XIq7FSqVEl9+/Z1dVsAAABczqmwEx8f7+p2AAAAXBNOzdmRpIsXL2rNmjWaPXu2Tp8+LUk6duyYzpw547LGAQAAXC2nRnYOHTqkrl276vDhw8rMzFSnTp3k5+enyZMn68KFC5o1a5ar2wkAAOAUp0Z2Ro8erRYtWigtLU3e3t728r59+2rt2rUuaxwAAMDVcvpqrP/+97/y8PBwKK9du7b++OMPlzQMAADAFZwa2cnNzVVOTk6B8qNHj8rPz++qGwUAAOAqToWdTp06afr06fbnNptNZ86c0bhx4/gJCQAAUK449TXWtGnT1L59ezVu3FgXLlzQoEGDtH//flWpUkULFixwdRsBAACc5lTYCQ0N1c6dO7VgwQJt375dubm5io6O1iOPPOIwYRkAAKCsORV2JMnb21vDhw/X8OHDXdkeAAAAl3Iq7HzwwQfFLh8yZIhTjQEAAHA1p8LO6NGjHZ5nZ2fr3Llz8vDwkI+PD2EHAACUG05djZWWlubwOHPmjH7++Wfde++9TFAGAADlitO/jZVfgwYN9MYbbxQY9QEAAChLLgs7klShQgUdO3bMlasEAAC4Kk7N2fn8888dnhtjlJycrBkzZqht27YuaRgAAIArOBV2HnjgAYfnNptNVatWVYcOHfTmm2+6ol0AAAAu4VTYyc3NdXU7AAAArgmXztkBAAAob5wa2XnuuedKXHfq1KnObAIAAMAlnAo7O3bs0Pbt23Xx4kU1bNhQkvTLL7+oQoUKat68ub2ezWZzTSsBAACc5FTY6dWrl/z8/DR37lwFBgZKunSjwccee0z33XefxowZ49JGAgAAOMupOTtvvvmmJk6caA86khQYGKjXX3+dq7EAAEC54tTITkZGho4fP64mTZo4lKempur06dMuaRhQnkUnJJV1EwAAJeTUyE7fvn312GOPacmSJTp69KiOHj2qJUuWKDo6Wv369XN1GwEAAJzm1MjOrFmzNHbsWD366KPKzs6+tCI3N0VHR2vKlCkubSAAAMDVcCrs+Pj4aObMmZoyZYoOHDggY4xuu+02+fr6urp9AAAAV+WqbiqYnJys5ORk3X777fL19ZUxxlXtAgAAcAmnws7JkycVFRWl22+/Xd27d1dycrIk6fHHH+eycwAAUK44FXaeffZZubu76/Dhw/Lx8bGXDxgwQCtXrnRZ4wAAAK6WU3N2Vq1apa+//lo1atRwKG/QoIEOHTrkkoYBAAC4glMjO2fPnnUY0cnz559/ytPT86obBQAA4CpOhZ37779fH3zwgf25zWZTbm6upkyZovbt27uscQAAAFfLqa+xpkyZonbt2mnr1q3KysrS888/r7179+qvv/7Sf//7X1e3EbiuuDsyAFiLUyM7jRs31u7du3XPPfeoU6dOOnv2rPr166cdO3aofv36rm4jAACA00o9spOdna3OnTtr9uzZmjBhwrVoEwAAgMuUemTH3d1de/bskc1muxbtAQAAcCmnvsYaMmSI4uLiXN0WAAAAl3NqgnJWVpbef/99rV69Wi1atCjwm1hTp051SeMAAACuVqnCzm+//aY6depoz549at68uSTpl19+cajD11sAbkQluQovbtjd16ElAFytVGGnQYMGSk5O1vr16yVd+nmIf//73woODr4mjQMAALhapZqzk/9XzVesWKGzZ8+6tEEAAACu5NQE5Tz5ww8AAEB5U6qwY7PZCszJYY4OAAAoz0o1Z8cYo2HDhtl/7PPChQt68sknC1yNtXTpUte1EAAA4CqUKuwMHTrU4fmjjz7q0sYAAAC4WqnCTnx8vEs3PnHiRC1dulQ//fSTvL291aZNG02aNEkNGza01zHGaMKECXr33XeVlpamli1b6u2331aTJk3sdTIzMzV27FgtWLBA58+fV1RUlGbOnKkaNWq4tL0AAODGc1UTlK/Wxo0b9dRTT+nbb7/V6tWrdfHiRXXu3NnhCq/Jkydr6tSpmjFjhpKSkhQSEqJOnTrp9OnT9joxMTFatmyZFi5cqM2bN+vMmTPq2bOncnJyyqJbAACgHLGZcnRJ1YkTJ1StWjVt3LhR999/v4wxCg0NVUxMjF544QVJl0ZxgoODNWnSJI0YMULp6emqWrWqPvzwQw0YMECSdOzYMdWsWVNfffWVunTpcsXtZmRkKCAgQOnp6fL397+mfUT5V5Kby6H8cNWN/lz1vnPjQeD6Ken/32U6spNfenq6JCkoKEiSdPDgQaWkpKhz5872Op6enoqMjNSWLVskSdu2bbP/Enue0NBQhYWF2evkl5mZqYyMDIcHAACwpnITdowxeu6553TvvfcqLCxMkpSSkiJJBe7QHBwcbF+WkpIiDw8PBQYGFlknv4kTJyogIMD+qFmzpqu7AwAAyolyE3aefvpp7d69WwsWLCiwLP+9fIwxV7y/T3F1XnrpJaWnp9sfR44ccb7hAACgXCsXYWfUqFH6/PPPtX79eocrqEJCQiSpwAhNamqqfbQnJCREWVlZSktLK7JOfp6envL393d4AAAAayrTsGOM0dNPP62lS5dq3bp1qlu3rsPyunXrKiQkRKtXr7aXZWVlaePGjWrTpo0kKSIiQu7u7g51kpOTtWfPHnsdAABw8yrVfXZc7amnntL8+fP12Wefyc/Pzz6CExAQIG9vb9lsNsXExCg2NlYNGjRQgwYNFBsbKx8fHw0aNMheNzo6WmPGjFHlypUVFBSksWPHKjw8XB07dizL7gG4DkpyFRVXSAE3tzINO++8844kqV27dg7l8fHxGjZsmCTp+eef1/nz5zVy5Ej7TQVXrVolPz8/e/1p06bJzc1N/fv3t99UMCEhQRUqVLheXQEAAOVUubrPTlnhPju4HPfZsZ6SjOxwnx3gxnND3mcHAADA1Qg7AADA0gg7AADA0gg7AADA0gg7AADA0sr00nMAuB64wg64uTGyAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI1Lz3FT4RJkALj5MLIDAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjbADAAAsjfvsAIALleReTnHD7r4OLQGQh5EdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaYQdAABgaW5l3QAAuNlEJyRdsU7csLuvQ0uAmwMjOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNIIOwAAwNLK9GqsTZs2acqUKdq2bZuSk5O1bNkyPfDAA/blxhhNmDBB7777rtLS0tSyZUu9/fbbatKkib1OZmamxo4dqwULFuj8+fOKiorSzJkzVaNGjTLoEcpSSa5wAQDcfMp0ZOfs2bO68847NWPGjEKXT548WVOnTtWMGTOUlJSkkJAQderUSadPn7bXiYmJ0bJly7Rw4UJt3rxZZ86cUc+ePZWTk3O9ugEAAMqxMh3Z6datm7p161boMmOMpk+frldeeUX9+vWTJM2dO1fBwcGaP3++RowYofT0dMXFxenDDz9Ux44dJUnz5s1TzZo1tWbNGnXp0uW69QUAAJRP5XbOzsGDB5WSkqLOnTvbyzw9PRUZGaktW7ZIkrZt26bs7GyHOqGhoQoLC7PXKUxmZqYyMjIcHgAAwJrKbdhJSUmRJAUHBzuUBwcH25elpKTIw8NDgYGBRdYpzMSJExUQEGB/1KxZ08WtBwAA5UW5DTt5bDabw3NjTIGy/K5U56WXXlJ6err9ceTIEZe0FQAAlD/lNuyEhIRIUoERmtTUVPtoT0hIiLKyspSWllZkncJ4enrK39/f4QEAAKyp3IadunXrKiQkRKtXr7aXZWVlaePGjWrTpo0kKSIiQu7u7g51kpOTtWfPHnsdAABwcyvTq7HOnDmjX3/91f784MGD2rlzp4KCglSrVi3FxMQoNjZWDRo0UIMGDRQbGysfHx8NGjRIkhQQEKDo6GiNGTNGlStXVlBQkMaOHavw8HD71VkAAODmVqZhZ+vWrWrfvr39+XPPPSdJGjp0qBISEvT888/r/PnzGjlypP2mgqtWrZKfn5/9NdOmTZObm5v69+9vv6lgQkKCKlSocN37AwAAyh+bMcaUdSPKWkZGhgICApSens78nRsYd1CGlcQNu7usmwCUeyX9/7tMR3YAAIUrSXgnEAElU24nKAMAALgCYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFgaYQcAAFiaW1k3AADgnOiEpCvWiRt293VoCVC+MbIDAAAsjbADAAAsjbADAAAsjbADAAAsjQnKuCGUZCImAACFYWQHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGmEHAABYGr96DgAWFp2QdMU6ccPuvg4tAcoOIzsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSuIMyylxJ7vAKAICzGNkBAACWRtgBAACWRtgBAACWRtgBAACWRtgBAACWxtVYAHCTK8kVkXHD7r4OLQGuDUZ2AACApRF2AACApRF2AACApRF2AACApTFBGU5jUiMA4EbAyA4AALA0y4zszJw5U1OmTFFycrKaNGmi6dOn67777ivrZt30+JFP4ObBaC/KK0uEnUWLFikmJkYzZ85U27ZtNXv2bHXr1k379u1TrVq1yrp5AAC4DKGy9CwRdqZOnaro6Gg9/vjjkqTp06fr66+/1jvvvKOJEyeWceuuL/4IAFwLVh2lLW/nTKvu57J2w4edrKwsbdu2TS+++KJDeefOnbVly5YyapXrufIPoLz9cQO4ebjqXHYjnqMIMmXnhg87f/75p3JychQcHOxQHhwcrJSUlEJfk5mZqczMTPvz9PR0SVJGRobL2/fUR9tcvs7rYfA768u6CQBQpJKcr111/i3J+fDtRyKuWCfr/BlXNKdEXPX/mav2YUn2jzPy+mmMKbbeDR928thsNofnxpgCZXkmTpyoCRMmFCivWbPmNWkbAMC15o0s6xY4oj3Fu9btOX36tAICAopcfsOHnSpVqqhChQoFRnFSU1MLjPbkeemll/Tcc8/Zn+fm5uqvv/5S5cqViwxIN6KMjAzVrFlTR44ckb+/f1k3p0zc7PvgZu+/xD6Q2AcS+8Cq/TfG6PTp0woNDS223g0fdjw8PBQREaHVq1erb9++9vLVq1erT58+hb7G09NTnp6eDmWVKlW6ls0sU/7+/pY6uJ1xs++Dm73/EvtAYh9I7AMr9r+4EZ08N3zYkaTnnntOgwcPVosWLdS6dWu9++67Onz4sJ588smybhoAAChjlgg7AwYM0MmTJ/XPf/5TycnJCgsL01dffaXatWuXddMAAEAZs0TYkaSRI0dq5MhyNiOrjHl6emrcuHEFvrK7mdzs++Bm77/EPpDYBxL74Gbvv81c6XotAACAGxg/BAoAACyNsAMAACyNsAMAACyNsAMAACyNsHMDS0tL0+DBgxUQEKCAgAANHjxYp06dKrJ+dna2XnjhBYWHh8vX11ehoaEaMmSIjh075lCvXbt2stlsDo+BAwde496UzMyZM1W3bl15eXkpIiJC33zzTbH1N27cqIiICHl5ealevXqaNWtWgTqffPKJGjduLE9PTzVu3FjLli27Vs13idLsg6VLl6pTp06qWrWq/P391bp1a3399dcOdRISEgq83zabTRcuXLjWXXFKafq/YcOGQvv2008/OdSz8jEwbNiwQvdBkyZN7HVutGNg06ZN6tWrl0JDQ2Wz2fTpp59e8TVWOheUtv9WPA+UmsENq2vXriYsLMxs2bLFbNmyxYSFhZmePXsWWf/UqVOmY8eOZtGiReann34yiYmJpmXLliYiIsKhXmRkpPn73/9ukpOT7Y9Tp05d6+5c0cKFC427u7t57733zL59+8zo0aONr6+vOXToUKH1f/vtN+Pj42NGjx5t9u3bZ9577z3j7u5ulixZYq+zZcsWU6FCBRMbG2t+/PFHExsba9zc3My33357vbpVKqXdB6NHjzaTJk0y33//vfnll1/MSy+9ZNzd3c327dvtdeLj442/v7/D+52cnHy9ulQqpe3/+vXrjSTz888/O/Tt4sWL9jpWPwZOnTrl0PcjR46YoKAgM27cOHudG+kYMMaYr776yrzyyivmk08+MZLMsmXLiq1vtXNBaftvtfOAMwg7N6h9+/YZSQ5/iImJiUaS+emnn0q8nu+//95IcjhRRkZGmtGjR7uyuS5xzz33mCeffNKhrFGjRubFF18stP7zzz9vGjVq5FA2YsQI06pVK/vz/v37m65duzrU6dKlixk4cKCLWu1apd0HhWncuLGZMGGC/Xl8fLwJCAhwVROvqdL2Py/spKWlFbnOm+0YWLZsmbHZbOb333+3l91Ix0B+JfnP3orngjwl6X9hbuTzgDP4GusGlZiYqICAALVs2dJe1qpVKwUEBGjLli0lXk96erpsNluB3wb76KOPVKVKFTVp0kRjx47V6dOnXdV0p2RlZWnbtm3q3LmzQ3nnzp2L7G9iYmKB+l26dNHWrVuVnZ1dbJ3S7MPrxZl9kF9ubq5Onz6toKAgh/IzZ86odu3aqlGjhnr27KkdO3a4rN2ucjX9b9asmapXr66oqCitX7/eYdnNdgzExcWpY8eOBe4wfyMcA86y2rngat3I5wFnEXZuUCkpKapWrVqB8mrVqhX4BfiiXLhwQS+++KIGDRrk8MNwjzzyiBYsWKANGzbo1Vdf1SeffKJ+/fq5rO3O+PPPP5WTk1Pgl+yDg4OL7G9KSkqh9S9evKg///yz2Dol3YfXkzP7IL8333xTZ8+eVf/+/e1ljRo1UkJCgj7//HMtWLBAXl5eatu2rfbv3+/S9l8tZ/pfvXp1vfvuu/rkk0+0dOlSNWzYUFFRUdq0aZO9zs10DCQnJ2vFihV6/PHHHcpvlGPAWVY7F1ytG/k84CzL/FyEVYwfP14TJkwotk5SUpIkyWazFVhmjCm0PL/s7GwNHDhQubm5mjlzpsOyv//97/Z/h4WFqUGDBmrRooW2b9+u5s2bl6Qb10z+vl2pv4XVz19e2nWWNWfbu2DBAo0fP16fffaZQ1Bu1aqVWrVqZX/etm1bNW/eXP/5z3/073//23UNd5HS9L9hw4Zq2LCh/Xnr1q115MgR/etf/9L999/v1DrLA2fbm5CQoEqVKumBBx5wKL/RjgFnWPFc4AyrnAdKi7BTzjz99NNXvPKpTp062r17t44fP15g2YkTJwp8OskvOztb/fv318GDB7Vu3TqHUZ3CNG/eXO7u7tq/f3+ZhZ0qVaqoQoUKBT5lpaamFtnfkJCQQuu7ubmpcuXKxda50j4sC87sgzyLFi1SdHS0Pv74Y3Xs2LHYurfccovuvvvucveJ7mr6f7lWrVpp3rx59uc3yzFgjNGcOXM0ePBgeXh4FFu3vB4DzrLaucBZVjgPOIuvscqZKlWqqFGjRsU+vLy81Lp1a6Wnp+v777+3v/a7775Tenq62rRpU+T684LO/v37tWbNGvsfenH27t2r7OxsVa9e3SV9dIaHh4ciIiK0evVqh/LVq1cX2d/WrVsXqL9q1Sq1aNFC7u7uxdYpbh+WFWf2gXTpk9ywYcM0f/589ejR44rbMcZo586dZfp+F8bZ/ue3Y8cOh77dDMeAdOnS619//VXR0dFX3E55PQacZbVzgTOsch5wWlnMioZrdO3a1TRt2tQkJiaaxMREEx4eXuDS84YNG5qlS5caY4zJzs42vXv3NjVq1DA7d+50uLwwMzPTGGPMr7/+aiZMmGCSkpLMwYMHzfLly02jRo1Ms2bNHC7XLQt5l9zGxcWZffv2mZiYGOPr62u/quTFF180gwcPttfPu9z02WefNfv27TNxcXEFLjf973//aypUqGDeeOMN8+OPP5o33nij3F5uakzp98H8+fONm5ubefvtt4u8lcD48ePNypUrzYEDB8yOHTvMY489Ztzc3Mx333133ft3JaXt/7Rp08yyZcvML7/8Yvbs2WNefPFFI8l88skn9jpWPwbyPProo6Zly5aFrvNGOgaMMeb06dNmx44dZseOHUaSmTp1qtmxY4f9qlKrnwtK23+rnQecQdi5gZ08edI88sgjxs/Pz/j5+ZlHHnmkwCW2kkx8fLwxxpiDBw8aSYU+1q9fb4wx5vDhw+b+++83QUFBxsPDw9SvX98888wz5uTJk9e3c0V4++23Te3atY2Hh4dp3ry52bhxo33Z0KFDTWRkpEP9DRs2mGbNmhkPDw9Tp04d88477xRY58cff2waNmxo3N3dTaNGjRz+IyyPSrMPIiMjC32/hw4daq8TExNjatWqZTw8PEzVqlVN586dzZYtW65jj0qnNP2fNGmSqV+/vvHy8jKBgYHm3nvvNcuXLy+wTisfA8ZcuteOt7e3effddwtd3412DOTdUqCo49rq54LS9t+K54HSshnz/8/SAgAAsCDm7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7AAAAEsj7ACwrHbt2ikmJqasmwGgjBF2AJRLvXr1KvLHChMTE2Wz2bR9+/br3CoANyLCDoByKTo6WuvWrdOhQ4cKLJszZ47uuusuNW/evAxaBuBGQ9gBUC717NlT1apVU0JCgkP5uXPntGjRIj3wwAN6+OGHVaNGDfn4+Cg8PFwLFiwodp02m02ffvqpQ1mlSpUctvHHH39owIABCgwMVOXKldWnTx/9/vvvrukUgDJB2AFQLrm5uWnIkCFKSEjQ5T/h9/HHHysrK0uPP/64IiIi9OWXX2rPnj164oknNHjwYH333XdOb/PcuXNq3769KlasqE2bNmnz5s2qWLGiunbtqqysLFd0C0AZIOwAKLeGDx+u33//XRs2bLCXzZkzR/369dOtt96qsWPH6q677lK9evU0atQodenSRR9//LHT21u4cKFuueUWvf/++woPD9cdd9yh+Ph4HT582KENAG4sbmXdAAAoSqNGjdSmTRvNmTNH7du314EDB/TNN99o1apVysnJ0RtvvKFFixbpjz/+UGZmpjIzM+Xr6+v09rZt26Zff/1Vfn5+DuUXLlzQgQMHrrY7AMoIYQdAuRYdHa2nn35ab7/9tuLj41W7dm1FRUVpypQpmjZtmqZPn67w8HD5+voqJiam2K+bbDabw1dikpSdnW3/d25uriIiIvTRRx8VeG3VqlVd1ykA1xVhB0C51r9/f40ePVrz58/X3Llz9fe//102m03ffPON+vTpo0cffVTSpaCyf/9+3XHHHUWuq2rVqkpOTrY/379/v86dO2d/3rx5cy1atEjVqlWTv7//tesUgOuKOTsAyrWKFStqwIABevnll3Xs2DENGzZMknTbbbdp9erV2rJli3788UeNGDFCKSkpxa6rQ4cOmjFjhrZv366tW7fqySeflLu7u335I488oipVqqhPnz765ptvdPDgQW3cuFGjR4/W0aNHr2U3AVxDhB0A5V50dLTS0tLUsWNH1apVS5L06quvqnnz5urSpYvatWunkJAQPfDAA8Wu580331TNmjV1//33a9CgQRo7dqx8fHzsy318fLRp0ybVqlVL/fr10x133KHhw4fr/PnzjPQANzCbyf8FNgAAgIUwsgMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACyNsAMAACzt/wPzZNUfPyQJegAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.32, Std: 0.19, Min: -0.37, Max: 1.37\n",
      "Recommended: Most values should be within [-5, 5] for accurate polynomial activation.\n"
     ]
    }
   ],
   "source": [
    "# Plot the distribution of pre-activation values for the first layer\n",
    "with torch.no_grad():\n",
    "    linear = model.model[0]\n",
    "    w = linear.weight.data.cpu().numpy()\n",
    "    b = linear.bias.data.cpu().numpy()\n",
    "    if w.ndim == 2:\n",
    "        w_vec = w[0]\n",
    "    else:\n",
    "        w_vec = w\n",
    "    w_vec = np.array(w_vec).flatten()\n",
    "    b_val = float(b[0]) if b.ndim > 0 else float(b)\n",
    "    pre_activations = X_test @ w_vec + b_val\n",
    "    plt.hist(pre_activations, bins=50, alpha=0.7)\n",
    "    plt.title('Distribution of Pre-Activation Values (First Layer)')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "    print(f\"Mean: {pre_activations.mean():.2f}, Std: {pre_activations.std():.2f}, Min: {pre_activations.min():.2f}, Max: {pre_activations.max():.2f}\")\n",
    "    print(\"Recommended: Most values should be within [-5, 5] for accurate polynomial activation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149bc9aa",
   "metadata": {},
   "source": [
    "### 3. Evaluate Model on Plaintext Test Data\n",
    "\n",
    "We first evaluate the trained model on unencrypted (plaintext) test data. This provides a baseline for accuracy and allows us to compare with encrypted inference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "401e794e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plaintext test accuracy: 0.8442\n"
     ]
    }
   ],
   "source": [
    "# 2. Evaluate on plaintext test data\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Plaintext test accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088ae273",
   "metadata": {},
   "source": [
    "### 4. Prepare Homomorphic Encryption Context\n",
    "\n",
    "We set up the TenSEAL context for CKKS homomorphic encryption. This context defines the encryption parameters, including polynomial modulus degree and coefficient modulus sizes, which control the security and precision of encrypted computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f403c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prepare TenSEAL context for encryption\n",
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "context.global_scale = 2 ** 21\n",
    "context.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e945b2",
   "metadata": {},
   "source": [
    "### 5. Encrypt the Test Data\n",
    "\n",
    "We encrypt each test sample using the TenSEAL context. This allows us to perform inference on encrypted data, ensuring that sensitive information is never exposed during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff4bdda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Encrypt the test data\n",
    "enc_X_test = [ts.ckks_vector(context, x.tolist()) for x in X_test_tensor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d12b2e",
   "metadata": {},
   "source": [
    "### 6. Define Encrypted Forward Pass\n",
    "\n",
    "Homomorphic encryption only supports addition and multiplication, so we cannot use standard non-linear activations (like sigmoid or ReLU). Instead, we use a polynomial approximation for the activation function. Here, we implement the encrypted forward pass for the first layer of the neural network, using a cubic polynomial to approximate the sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "717af373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypted_first_layer_forward(model, enc_x, context):\n",
    "    # Only run the first linear layer + activation under encryption\n",
    "    linear = model.model[0]\n",
    "    w = linear.weight.data.cpu().numpy()\n",
    "    b = linear.bias.data.cpu().numpy()\n",
    "    # Ensure w_vec is a 1D list matching the input vector length\n",
    "    if w.ndim == 2:\n",
    "        w_vec = w[0]\n",
    "    else:\n",
    "        w_vec = w\n",
    "    w_vec = np.array(w_vec).flatten().tolist()\n",
    "    b_val = float(b[0]) if b.ndim > 0 else float(b)\n",
    "    # Debug: print shapes if error persists\n",
    "    # print(f\"enc_x len: {len(enc_x.decrypt())}, w_vec len: {len(w_vec)}\")\n",
    "    enc_out = enc_x.dot(w_vec) + b_val\n",
    "    # Polynomial activation\n",
    "    poly_coeffs = [0.5, 0.197, 0, -0.004]\n",
    "    enc_out = enc_out.polyval(poly_coeffs)\n",
    "    return enc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6115b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def safe_encrypted_forward(model, enc_x, context, max_layers=None, poly_coeffs=[0.5, 0.197, 0, -0.004]):\n",
    "    \"\"\"\n",
    "    Encrypted forward pass with error handling and timing.\n",
    "    Returns output, layers_run, runtime, and error (if any).\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    try:\n",
    "        enc_out, layers_run = encrypted_forward_modular(model, enc_x, context, max_layers, poly_coeffs)\n",
    "        runtime = time.time() - start\n",
    "        return enc_out, layers_run, runtime, None\n",
    "    except Exception as e:\n",
    "        runtime = time.time() - start\n",
    "        print(f\"[Error] Encrypted forward failed: {e}\")\n",
    "        return None, 0, runtime, str(e)\n",
    "\n",
    "# Example usage for a single sample:\n",
    "# enc_out, layers_run, runtime, error = safe_encrypted_forward(model, enc_X_test[0], context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45ac8aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypted_forward_modular(model, enc_x, context, max_layers=None, poly_coeffs=[0.5, 0.197, 0, -0.004]):\n",
    "    \"\"\"\n",
    "    Run as many layers as possible under HE (linear + polynomial activation),\n",
    "    stopping at the first unsupported operation or at max_layers.\n",
    "    Returns the encrypted output and the number of layers run under HE.\n",
    "    \"\"\"\n",
    "    layers = list(model.model)\n",
    "    enc_out = enc_x\n",
    "    layers_run = 0\n",
    "    for i, layer in enumerate(layers):\n",
    "        # Only support Linear and polynomial activation\n",
    "        if isinstance(layer, torch.nn.Linear):\n",
    "            w = layer.weight.data.cpu().numpy()\n",
    "            b = layer.bias.data.cpu().numpy()\n",
    "            if w.ndim == 2:\n",
    "                w_vec = w[0]\n",
    "            else:\n",
    "                w_vec = w\n",
    "            w_vec = np.array(w_vec).flatten().tolist()\n",
    "            b_val = float(b[0]) if b.ndim > 0 else float(b)\n",
    "            enc_out = enc_out.dot(w_vec) + b_val\n",
    "            layers_run += 1\n",
    "        elif isinstance(layer, torch.nn.Sigmoid) or isinstance(layer, torch.nn.ReLU):\n",
    "            # Only polynomial activations are supported under HE\n",
    "            enc_out = enc_out.polyval(poly_coeffs)\n",
    "            layers_run += 1\n",
    "        else:\n",
    "            # Stop at unsupported layer\n",
    "            break\n",
    "        if max_layers is not None and layers_run >= max_layers:\n",
    "            break\n",
    "    return enc_out, layers_run\n",
    "\n",
    "def get_supported_he_layers(model):\n",
    "    \"\"\"\n",
    "    Returns the number of layers that can be run under HE (Linear + polynomial activation).\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for layer in model.model:\n",
    "        if isinstance(layer, torch.nn.Linear) or isinstance(layer, torch.nn.Sigmoid) or isinstance(layer, torch.nn.ReLU):\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b556bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 5951/6033 [09:41<00:07, 10.69it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Evaluate on encrypted test data (for a single-layer model)\n",
    "y_pred_enc = []\n",
    "for enc_x in tqdm(enc_X_test):\n",
    "    enc_out = encrypted_first_layer_forward(model, enc_x, context)\n",
    "    out = enc_out.decrypt()\n",
    "    if isinstance(out, list):\n",
    "        out = out[0]\n",
    "    y_pred_enc.append(int(out > 0.5))\n",
    "acc_enc = accuracy_score(y_test, y_pred_enc)\n",
    "print(f\"Encrypted test accuracy (first layer only): {acc_enc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528a9f6a",
   "metadata": {},
   "source": [
    "### 7. Evaluate Model on Encrypted Test Data\n",
    "\n",
    "We now perform inference on the encrypted test set using the encrypted forward pass. The predictions are decrypted only for accuracy calculation. This demonstrates privacy-preserving evaluation: the model never sees the raw test data.\n",
    "\n",
    "**Performance Note:** Homomorphic encryption is much slower than plaintext computation. For practical reasons, we only encrypt the test set for demonstration. Full encrypted training or multi-layer encrypted inference is currently impractical for deep models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044aff12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating fairness metrics for sex in adult\n",
      "Calculating fairness metrics for race in adult\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from helpers.compute_fairness import calculate_all_fairness_metrics\n",
    "\n",
    "# Build df_test with all required columns for fairness analysis\n",
    "columns = df.drop(feat_dict['adult']['target'], axis=1).columns\n",
    "\n",
    "df_test = pd.DataFrame(X_test, columns=columns)\n",
    "df_test[feat_dict[\"adult\"][\"target\"]] = y_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51217aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute fairness metrics for plaintext predictions\n",
    "plain_df_test = pd.DataFrame(X_test, columns=columns)\n",
    "plain_df_test[feat_dict[\"adult\"][\"target\"]] = y_test.values\n",
    "plain_df_test['predicted_label'] = model.predict(X_test)\n",
    "plain_fairness_metrics = calculate_all_fairness_metrics(\n",
    "    model, df_test=plain_df_test, dataset_name=\"adult\"\n",
    ")\n",
    "\n",
    "# Compute fairness metrics for encrypted predictions\n",
    "# (Assume y_pred_enc was computed in the encrypted evaluation cell)\n",
    "encrypted_df_test = pd.DataFrame(X_test, columns=columns)\n",
    "encrypted_df_test[feat_dict[\"adult\"][\"target\"]] = y_test.values\n",
    "encrypted_df_test['predicted_label'] = y_pred_enc\n",
    "encrypted_fairness_metrics = calculate_all_fairness_metrics(\n",
    "    model, df_test=encrypted_df_test, dataset_name=\"adult\"\n",
    ")\n",
    "\n",
    "print(\"Plaintext Fairness Metrics:\")\n",
    "print(plain_fairness_metrics)\n",
    "print(\"\\nEncrypted Fairness Metrics:\")\n",
    "print(encrypted_fairness_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26dfb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example: Visualize group-wise accuracy for a sensitive attribute (e.g., 'sex')\n",
    "sensitive_attr = 'sex'\n",
    "groups = df_test[sensitive_attr].unique()\n",
    "plain_group_acc = []\n",
    "enc_group_acc = []\n",
    "for group in groups:\n",
    "    idx = df_test[sensitive_attr] == group\n",
    "    plain_group_acc.append(accuracy_score(df_test.loc[idx, feat_dict['adult']['target']], plain_df_test.loc[idx, 'predicted_label']))\n",
    "    enc_group_acc.append(accuracy_score(df_test.loc[idx, feat_dict['adult']['target']], encrypted_df_test.loc[idx, 'predicted_label']))\n",
    "\n",
    "x = np.arange(len(groups))\n",
    "width = 0.35\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, plain_group_acc, width, label='Plaintext')\n",
    "rects2 = ax.bar(x + width/2, enc_group_acc, width, label='Encrypted')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title(f'Group-wise Accuracy by {sensitive_attr.capitalize()}')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(groups)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e887c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Measure runtime for plaintext inference\n",
    "start_plain = time.time()\n",
    "y_pred_plain = model.predict(X_test)\n",
    "plain_runtime = time.time() - start_plain\n",
    "\n",
    "# Measure runtime for encrypted inference (first layer only)\n",
    "start_enc = time.time()\n",
    "y_pred_enc = []\n",
    "for enc_x in enc_X_test:\n",
    "    enc_out, _ = encrypted_forward_modular(model, enc_x, context)\n",
    "    out = enc_out.decrypt()\n",
    "    if isinstance(out, list):\n",
    "        out = out[0]\n",
    "    y_pred_enc.append(int(out > 0.5))\n",
    "enc_runtime = time.time() - start_enc\n",
    "\n",
    "# Compute accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_plain = accuracy_score(y_test, y_pred_plain)\n",
    "acc_enc = accuracy_score(y_test, y_pred_enc)\n",
    "\n",
    "# Display fairness metrics (already computed above)\n",
    "plain_metrics = plain_fairness_metrics\n",
    "enc_metrics = encrypted_fairness_metrics\n",
    "\n",
    "# Combine results in a DataFrame for easy comparison\n",
    "results_df = pd.DataFrame({\n",
    "    'Type': ['Plaintext', 'Encrypted'],\n",
    "    'Accuracy': [acc_plain, acc_enc],\n",
    "    'Runtime (s)': [plain_runtime, enc_runtime],\n",
    "    'Fairness Metric Example': [plain_metrics.get('demographic_parity_difference', 'N/A'), enc_metrics.get('demographic_parity_difference', 'N/A')]\n",
    "})\n",
    "\n",
    "print(\"\\nComparison of Plaintext vs. Encrypted Inference:\")\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdbfca9",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary> Understanding Fairness Metrics</summary>\n",
    "\n",
    "- **Demographic Parity Difference:** Measures the difference in positive prediction rates between sensitive groups (e.g., male vs. female). A value close to 0 indicates fairness.\n",
    "- **Equal Opportunity Difference:** Compares true positive rates between groups. A value close to 0 means both groups have equal opportunity for positive outcomes.\n",
    "- **Average Odds Difference:** Averages the differences in both true positive and false positive rates between groups. Lower values indicate fairer models.\n",
    "\n",
    "These metrics help assess whether the model's predictions are biased with respect to sensitive attributes, both in plaintext and encrypted inference.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ccaea6",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary> Practical Considerations </summary>\n",
    "\n",
    "- **Current Limitations:**\n",
    "  - For multi-layer neural networks, implementing a full encrypted forward pass is challenging due to the limitations of homomorphic encryption (no support for non-polynomial activations, no efficient batching for arbitrary layers). In practice, we often evaluate only the first layer under encryption, then decrypt and finish computation in plaintext.\n",
    "  - The above example demonstrates that encrypted inference can achieve similar accuracy to plaintext inference, but at a much higher computational cost. Try printing or tabulating both accuracy and runtime for plaintext vs encrypted inference to see the tradeoff.\n",
    "  - This workflow enables privacy-preserving ML experiments, and can be extended to study fairness (e.g., by evaluating group-wise accuracy on encrypted data) and feature attribution (e.g., by perturbing encrypted inputs and observing the effect on predictions).\n",
    "  - Encrypted inference is much slower than plaintext, and requires careful parameter tuning to balance security, accuracy, and efficiency.\n",
    "\n",
    "- **What Would Enable Deeper Encrypted Inference?**\n",
    "  - More efficient HE schemes or hardware acceleration.\n",
    "  - Better polynomial approximations for activations, or new network architectures designed for HE.\n",
    "  - Improved ciphertext management (e.g., bootstrapping) to allow deeper computations.\n",
    "\n",
    "- **Suggestions for Extension:**\n",
    "  - Try different polynomial degrees for activation and observe the effect on accuracy and fairness.\n",
    "  - Experiment with other datasets or sensitive attributes.\n",
    "  - Implement encrypted feature attribution by perturbing encrypted inputs and measuring prediction changes.\n",
    "  - Automate runtime and fairness reporting for scientific comparison.\n",
    "</details>\n",
    "\n",
    "**Summary:**\n",
    "This notebook provides a foundation for privacy-preserving and fair ML experiments using homomorphic encryption. With further research and engineering, these techniques can be extended to more complex models and real-world applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "encryptML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
